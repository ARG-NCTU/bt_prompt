import re
import argparse
import os
from bt_prompt.bt_generator import BTGenerator

def replace_placeholder_in_prompt(prompt_template_path, task_description_path):
	"""
	Replace the placeholder in the prompt template with the content of the task requirement description.

	Args:
		prompt_template_path (str): Path to the prompt template file.
		task_description_path (str): Path to the task requirement description file.

	Returns:
		str: The modified prompt content.
	"""
	with open(prompt_template_path, 'r') as template_file:
		prompt_content = template_file.read()

	with open(task_description_path, 'r') as description_file:
		task_description = description_file.read()

	# Replace the placeholder text with the actual task description
	modified_prompt = prompt_content.replace("Put Task Requirement Description.txt here!", task_description)

	return modified_prompt

def custom_write_tree(response, output_dir, count):
	"""
	Custom function to extract and save the symbolic behavior trees from the response to separate files.

	Args:
		response (str): The response generated by the LLM.
		output_dir (str): Directory where the output files will be saved.
		count (int): Index for the generated output files.
	
	Returns:
		None
	"""
	# Splitting the response into sections based on "2."
	sections = response.split('2.')
	
	if len(sections) == 2:
		# Extracting the content between the triple backticks in each section
		tree_1 = sections[0].split('```')[1].strip()
		tree_2 = sections[1].split('```')[1].strip()

		# Replace spaces with tabs and remove blank lines
		tree_1_with_tabs = "\n".join([line.replace('    ', '\t') for line in tree_1.splitlines() if line.strip()])
		tree_2_with_tabs = "\n".join([line.replace('    ', '\t') for line in tree_2.splitlines() if line.strip()])

		# Write tree 1 to a file
		tree_1_file = os.path.join(output_dir, f"expanded_inspection_tree_{count}.tree")
		with open(tree_1_file, 'w+') as file:
			file.write(tree_1_with_tabs)
		print(f"Expanded Inspection Tree saved to {tree_1_file}")

		# Write tree 2 to a file
		tree_2_file = os.path.join(output_dir, f"final_tree_with_inspection_subtree_{count}.tree")
		with open(tree_2_file, 'w+') as file:
			file.write(tree_2_with_tabs)
		print(f"Final Tree with Inspection Subtree Integrated saved to {tree_2_file}")
	else:
		print("Response format is not as expected.")

def main(args):
	"""
	Generates a response using OpenAI's GPT-4 model based on the provided prompt.

	Args:
		args (object): An object containing the necessary arguments for generating the response.
			- prompt_dir (str): Directory to store generated outputs.
			- generate_dir (str): Directory to store generated outputs.
			- model_name (str): Model name for OpenAI API.
			- sub_tree_dir (str): Directory for subtree configuration.
			- count (int): Number of times to generate outputs.
			- temp (float): Temperature for response generation.

	Returns:
		None
	"""
	# Get the paths for the template and task description files
	prompt_template_path = os.path.join(args.prompt_dir, args.prompt_file)
	task_description_path = os.path.join(args.prompt_dir, "Task_Requirement_Description.txt")

	# Generate the modified prompt by replacing the placeholder
	modified_prompt = replace_placeholder_in_prompt(prompt_template_path, task_description_path)

	# Save the modified prompt to a temporary file or directly use it
	temp_prompt_file = os.path.join(args.prompt_dir, "modified_prompt.txt")
	with open(temp_prompt_file, 'w+') as file:
		file.write(modified_prompt)

	bt_gen = BTGenerator(
		path=args.generate_dir,
		sub_tree_dir_path=args.sub_tree_dir,
		model=args.model_name,
		temperature=args.temp,
	)

	# Pass the path to the modified prompt file
	bt_gen.read_prompt(prompt_path=temp_prompt_file)

	for i in range(args.count):
		print(f"Generating BT {i}")
		response = bt_gen.chat_generate()

		bt_gen.write_response(response, count=i)
		bt_gen.write_raw(response, count=i)
		# Use custom write tree function
		custom_write_tree(response.choices[0].message.content, output_dir=args.generate_dir, count=i)

if __name__ == "__main__":
	parser = argparse.ArgumentParser(
		description="Generate LLM responses and process trees.")
	parser.add_argument(
		"--prompt_dir",
		type=str,
		default=os.path.join(os.path.dirname(os.path.abspath(__file__)), "../config/semi_auto_aerial_manipulation/"),
		help="Directory to store generated outputs.")
	parser.add_argument(
		"--generate_dir",
		type=str,
		default=os.path.join(os.path.dirname(os.path.abspath(__file__)), "../../bt_execution/config/aerial_manipulation/"),
		help="Directory to store generated outputs.")
	parser.add_argument(
		"--model_name",
		type=str,
		default="gpt-4o-2024-08-06",
		help="Model name for OpenAI API.")
	parser.add_argument(
		"--sub_tree_dir",
		type=str,
		default=os.path.join(os.path.dirname(os.path.abspath(__file__)), "../config/subtree/"),
		help="Directory for subtree configuration.")
	parser.add_argument(
		"--prompt_file",
		type=str,
		default="prompt_template.txt",
		help="File name containing the prompt."
	)
	parser.add_argument(
		"--count",
		type=int,
		default=1,
		help="Number of times to generate outputs.")
	parser.add_argument(
		"--temp",
		type=float,
		default=1.0,
		help="Temperature for response generation.")
	args = parser.parse_args()

	main(args)
